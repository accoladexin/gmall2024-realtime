import com.acco.gmall.realtime.common.base.BaseAPP;
import com.acco.gmall.realtime.common.constant.Constant;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.Table;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

/**
 * ClassName: testdwd
 * Description: None
 * Package: PACKAGE_NAME
 *
 * @author : Accoalde
 * @version: 1.0
 * Creat time 2024-03-02 22:12
 */
public class testdwd {
    public static void main(String[] args) {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(4);
        StreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(env);
        //从kafka读数据
        tableEnvironment.executeSql("CREATE TABLE topic_db (\n" +
                "  `database` String,\n" +
                "  `table` STRING,\n" +
                "  `ts` bigint,\n" +
                "  `data` map<STRING,STRING>,\n" +
                "  `old` map<STRING,STRING>\n" +
                ") WITH (\n" +
                "  'connector' = 'kafka',\n" +
                "  'topic' = 'topic_db',\n" +
                "  'properties.bootstrap.servers' = 'hadoop102:9092',\n" +
                "  'properties.group.id' = 'testGroup1',\n" +
                "  'scan.startup.mode' = 'earliest-offset',\n" +
                "  'format' = 'json'\n" +
                ")");
        Table table = tableEnvironment.sqlQuery("select * from topic_db where `database`='gmall' and `table`='comment_info'");
        table.execute().print();
    }
}
